{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.4.5'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import gensim\n",
    "tf.__version__\n",
    "import nltk  # 영어 자연어처리 패키지\n",
    "nltk.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `gensim.topic_coherence.text_analysis.Word2Vec('hi')` not found.\n"
     ]
    }
   ],
   "source": [
    "?gensim.topic_coherence.text_analysis.Word2Vec('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()  # nltk data 다운로드\n",
    "# nltk.download('treebank')  # treebank 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.5.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import konlpy\n",
    "konlpy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화, 정제, 정규화\n",
    "# 토큰(단어)화 : 어절, 단어, 문장, 문단\n",
    "\n",
    "# 단어 토큰화 : 구두점, 특수문자 제거\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "from nltk.tokenize import TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nltk.tokenize \\ word_tokenize :  ['Mr.', 'Jone', \"'s\", 'Do', \"n't\", 'be', '!', '?', '$', '100', '3.14']\n",
      "nltk.tokenize / WordPunctTokenizer :  ['Mr', '.', 'Jone', \"'\", 's', 'Don', \"'\", 't', 'be', '!?', '$', '100', '3', '.', '14']\n",
      "tensorflow.keras.preprocessing.text / text_to_word_sequence :  ['mr', \"jone's\", \"don't\", 'be', '100', '3', '14']\n",
      "nltk.tokenize / TreebankWordTokenizer :  ['Mr.', 'Jone', \"'s\", 'Do', \"n't\", 'be', '!', '?', '$', '100', '3.14']\n"
     ]
    }
   ],
   "source": [
    "# 가장 많이 쓰임\n",
    "print('nltk.tokenize \\ word_tokenize : ',word_tokenize(\"Mr. Jone's Don't be!?  $100  3.14\"))\n",
    "\n",
    "# 클래스 객체 생성\n",
    "wpt=WordPunctTokenizer()\n",
    "print('nltk.tokenize / WordPunctTokenizer : ',wpt.tokenize(\"Mr. Jone's Don't be!?  $100  3.14\"))\n",
    "\n",
    "# keras token화\n",
    "print('tensorflow.keras.preprocessing.text / text_to_word_sequence : ',text_to_word_sequence(\"Mr. Jone's Don't be!?  $100  3.14\"))\n",
    "\n",
    "# 표준.\n",
    "twt=TreebankWordTokenizer()\n",
    "print('nltk.tokenize / TreebankWordTokenizer : ',twt.tokenize(\"Mr. Jone's Don't be!?  $100  3.14\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장단위 토큰화\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Python is an interpreted, high-level, general-purpose programming language.', \"Created by Guido van Rossum and first released in 1991, Python's design philosophy emphasizes code readability with its notable use of significant whitespace.\", 'Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects.']\n"
     ]
    }
   ],
   "source": [
    "text = \"Python is an interpreted, high-level, general-purpose programming language. Created by Guido van Rossum and first released in 1991, Python's design philosophy emphasizes code readability with its notable use of significant whitespace. Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects.\"\n",
    "\n",
    "print(sent_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한국어 토큰화\n",
    "# 조사 : 그녀가(에게, 를, 와, 는 ...)\n",
    "# 아버지가방에들어가.. \n",
    "\n",
    "# 토큰화 작업 : 형태소 (가장 작은 말의 단위) 고려\n",
    "# -> 자립형태소 / 의존형태소\n",
    "\n",
    "# 길동이가 파이썬을 합니다\n",
    "# 자립형태소(길동이, 파이썬) / 의존형태소 (조사, 어미,..)\n",
    "\n",
    "# 품사 태깅(tagging), fly\n",
    "# : 토큰화 과정에서 단어가 어떤 품사로 쓰여지는지 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Python', 'is', 'an', 'interpreted', ',', 'high-level', ',', 'general-purpose', 'programming', 'language', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Python', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('an', 'DT'),\n",
       " ('interpreted', 'JJ'),\n",
       " (',', ','),\n",
       " ('high-level', 'JJ'),\n",
       " (',', ','),\n",
       " ('general-purpose', 'JJ'),\n",
       " ('programming', 'NN'),\n",
       " ('language', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Python is an interpreted, high-level, general-purpose programming language.'\n",
    "\n",
    "print(word_tokenize(text))\n",
    "\n",
    "# 태깅\n",
    "from nltk.tag import pos_tag\n",
    "pos_tag(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형태소 분석기\n",
    "# : Okt, Mecab, Kkma\n",
    "# : 단어 토큰화가 아님 / 형태소 토큰화를 하는 것임\n",
    "\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['오늘', '은', '수요일', ',', '내일', '은', '목요일', '입니다', '.']\n",
      "[('오늘', 'Noun'), ('은', 'Josa'), ('수요일', 'Noun'), (',', 'Punctuation'), ('내일', 'Noun'), ('은', 'Josa'), ('목요일', 'Noun'), ('입니다', 'Adjective'), ('.', 'Punctuation')]\n",
      "['오늘', '수요일', '내일', '목요일']\n"
     ]
    }
   ],
   "source": [
    "okt = Okt()\n",
    "print(okt.morphs(\"오늘은 수요일, 내일은 목요일입니다.\"))\n",
    "\n",
    "# 태깅까지\n",
    "print(okt.pos(\"오늘은 수요일, 내일은 목요일입니다.\"))\n",
    "\n",
    "# 명사만\n",
    "print(okt.nouns(\"오늘은 수요일, 내일은 목요일입니다.\"))\n",
    "\n",
    "# konlpy.org 사이트 참고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 정제(전처리) : 불필요한 형태소 제거, 단어 통일 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSA (Latent Semantic Analysis) 잠재의미분석\n",
    "# : '토픽'으로 유사도를 구하는 알고리즘\n",
    "\n",
    "# SVD (Singular Value Decomposition) 특이값 분해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 9)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 임의의 DTM 생성\n",
    "A = np.array([[0,0,0,1,0,1,1,0,0],\n",
    "              [0,0,0,1,1,0,1,0,0],\n",
    "              [0,1,1,0,2,0,0,0,0],\n",
    "              [1,0,0,0,0,0,0,1,1]])\n",
    "A.shape  # 4, 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.24,  0.75,  0.  , -0.62],\n",
       "        [-0.51,  0.44, -0.  ,  0.74],\n",
       "        [-0.83, -0.49, -0.  , -0.27],\n",
       "        [-0.  , -0.  ,  1.  ,  0.  ]]),\n",
       " array([2.69, 2.05, 1.73, 0.77]),\n",
       " array([[-0.  , -0.31, -0.31, -0.28, -0.8 , -0.09, -0.28, -0.  , -0.  ],\n",
       "        [ 0.  , -0.24, -0.24,  0.58, -0.26,  0.37,  0.58, -0.  , -0.  ],\n",
       "        [ 0.58, -0.  ,  0.  ,  0.  , -0.  ,  0.  , -0.  ,  0.58,  0.58],\n",
       "        [ 0.  , -0.35, -0.35,  0.16,  0.25, -0.8 ,  0.16, -0.  , -0.  ],\n",
       "        [-0.  , -0.78, -0.01, -0.2 ,  0.4 ,  0.4 , -0.2 ,  0.  ,  0.  ],\n",
       "        [-0.29,  0.31, -0.78, -0.24,  0.23,  0.23,  0.01,  0.14,  0.14],\n",
       "        [-0.29, -0.1 ,  0.26, -0.59, -0.08, -0.08,  0.66,  0.14,  0.14],\n",
       "        [-0.5 , -0.06,  0.15,  0.24, -0.05, -0.05, -0.19,  0.75, -0.25],\n",
       "        [-0.5 , -0.06,  0.15,  0.24, -0.05, -0.05, -0.19, -0.25,  0.75]]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U, s, VT = np.linalg.svd(A, full_matrices=True)  # full SVD, truncated SVD\n",
    "U, s, VT\n",
    "U.round(2), s.round(2), VT.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 9)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.shape   # 4, 4\n",
    "s.shape   # 4,\n",
    "VT.shape  # 9, 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.69, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 2.05, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 1.73, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.77, 0.  , 0.  , 0.  , 0.  , 0.  ]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = np.zeros([4,9])\n",
    "S[:4,:4] = np.diag(s)\n",
    "S.round(2)  # 특이값 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.   -0.31 -0.31 -0.28 -0.8  -0.09 -0.28 -0.   -0.  ]\n",
      " [ 0.   -0.24 -0.24  0.58 -0.26  0.37  0.58 -0.   -0.  ]\n",
      " [ 0.58 -0.    0.    0.   -0.    0.   -0.    0.58  0.58]\n",
      " [ 0.   -0.35 -0.35  0.16  0.25 -0.8   0.16 -0.   -0.  ]\n",
      " [-0.   -0.78 -0.01 -0.2   0.4   0.4  -0.2   0.    0.  ]\n",
      " [-0.29  0.31 -0.78 -0.24  0.23  0.23  0.01  0.14  0.14]\n",
      " [-0.29 -0.1   0.26 -0.59 -0.08 -0.08  0.66  0.14  0.14]\n",
      " [-0.5  -0.06  0.15  0.24 -0.05 -0.05 -0.19  0.75 -0.25]\n",
      " [-0.5  -0.06  0.15  0.24 -0.05 -0.05 -0.19 -0.25  0.75]]\n"
     ]
    }
   ],
   "source": [
    "print(VT.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  1., -0.,  1.,  1.,  0.,  0.],\n",
       "       [ 0., -0., -0.,  1.,  1., -0.,  1., -0., -0.],\n",
       "       [ 0.,  1.,  1., -0.,  2., -0., -0.,  0.,  0.],\n",
       "       [ 1., -0.,  0.,  0., -0.,  0., -0.,  1.,  1.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(np.dot(U,S),VT).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 1, 0, 1, 0, 0],\n",
       "       [0, 1, 1, 0, 2, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 1, 1]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 두 행렬이 같은지 판단하는 함수\n",
    "np.allclose(A, np.dot(np.dot(U,S),VT).round(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.  , -0.31, -0.31, -0.28, -0.8 , -0.09, -0.28, -0.  , -0.  ],\n",
       "       [ 0.  , -0.24, -0.24,  0.58, -0.26,  0.37,  0.58, -0.  , -0.  ],\n",
       "       [ 0.58, -0.  ,  0.  ,  0.  , -0.  ,  0.  , -0.  ,  0.58,  0.58],\n",
       "       [ 0.  , -0.35, -0.35,  0.16,  0.25, -0.8 ,  0.16, -0.  , -0.  ],\n",
       "       [-0.  , -0.78, -0.01, -0.2 ,  0.4 ,  0.4 , -0.2 ,  0.  ,  0.  ],\n",
       "       [-0.29,  0.31, -0.78, -0.24,  0.23,  0.23,  0.01,  0.14,  0.14],\n",
       "       [-0.29, -0.1 ,  0.26, -0.59, -0.08, -0.08,  0.66,  0.14,  0.14],\n",
       "       [-0.5 , -0.06,  0.15,  0.24, -0.05, -0.05, -0.19,  0.75, -0.25],\n",
       "       [-0.5 , -0.06,  0.15,  0.24, -0.05, -0.05, -0.19, -0.25,  0.75]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VT.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.   -0.17 -0.17  1.08  0.12  0.62  1.08 -0.   -0.  ]\n",
      " [ 0.    0.2   0.2   0.91  0.86  0.45  0.91  0.    0.  ]\n",
      " [ 0.    0.93  0.93  0.03  2.05 -0.17  0.03  0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.   -0.    0.    0.    0.  ]]\n",
      "[[0 0 0 1 0 1 1 0 0]\n",
      " [0 0 0 1 1 0 1 0 0]\n",
      " [0 1 1 0 2 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# 절단된 SVD\n",
    "# 토픽을 2개로 하고싶다\n",
    "S = S[:2,:2]  # 2, 2  토픽 2개\n",
    "U = U[:,:2]   # 4, 2  문서 4개, 토픽 2개\n",
    "# U의 의미는 4개 문서 각각에 대한 잠재된 의미를 표현하고 있는 수치문서 백터\n",
    "\n",
    "VT = VT[:2,:] # 2, 4  단어 4개, 토픽 2개\n",
    "# VT의 각 열은 잠재 의미를 나타내기 위한 수치화 된 단어 백터\n",
    "\n",
    "Aprime = np.dot(np.dot(U,S),VT).round(2)\n",
    "print(Aprime)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.  , -0.83, -0.83, -0.75, -2.16, -0.24, -0.75, -0.  , -0.  ],\n",
       "       [ 0.  , -0.49, -0.49,  1.2 , -0.53,  0.75,  1.2 , -0.  , -0.  ]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(S,VT).round(2)\n",
    "# (2,9)행의 scatter을 그리고 각 좌표끼리의 cos유사도를 구함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "        돈     사랑    저는    좋아요\n",
    "줄거리1  0       1      1       1\n",
    "줄거리2  1       0      1       1\n",
    "줄거리3  2       0      2       2\n",
    "'''\n",
    "# cos 유사도 공식\n",
    "# 문서 내접 / 각 문서벡터의 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "mov1 = np.array([0,1,1,1])\n",
    "mov2 = np.array([1,0,1,1])\n",
    "mov3 = np.array([2,0,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666667"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(mov1,mov2) / (norm(mov1)*norm(mov2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000002"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(mov2,mov3) / (norm(mov2)*norm(mov3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(X,Y):\n",
    "    return np.dot(X,Y) / (norm(X)*norm(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666667\n",
      "0.6666666666666667\n",
      "1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "print(cos_sim(mov1, mov2))\n",
    "print(cos_sim(mov1, mov3))\n",
    "print(cos_sim(mov2, mov3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/the-movies-dataset/movies_metadata.csv')\n",
    "\n",
    "data = data[:25000]\n",
    "data['overview'].isnull().sum()  # 135\n",
    "\n",
    "# 결측치 채우기\n",
    "data['overview'] = data['overview'].fillna('')\n",
    "\n",
    "data['overview'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 영어 tf-idf객체 생성\n",
    "tfidf = TfidfVectorizer(stop_words='english').fit(data['overview'])\n",
    "\n",
    "# tf-idf 메트릭스 생성\n",
    "## 원래는 be동사 처리나 동사 형태 처리도 필요함 // 약식으로 test\n",
    "\n",
    "t=tfidf.transform(data['overview']) # 20000, 47487\n",
    "\n",
    "t_array = t.toarray()\n",
    "t_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Toy Story'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['title'][0]\n",
    "# Toy Story와 가장 코사인 유사도가 큰 영화 10편을 추출 -> 영화 제목과 유사도 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.linalg.svd(t_array, full_matrices=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.5258228774915119, 'Toy Story 3'),\n",
       " (0.4626387756002305, 'Toy Story 2'),\n",
       " (0.27955408709340457, 'The 40 Year Old Virgin'),\n",
       " (0.2006858706012685, 'The Champ'),\n",
       " (0.18272966895459847, 'Rebel Without a Cause'),\n",
       " (0.15689197655065487, 'For Your Consideration'),\n",
       " (0.15273435380284647, 'Condorman'),\n",
       " (0.1431988524037047, 'Man on the Moon'),\n",
       " (0.13751066537587156, 'Malice'),\n",
       " (0.13360660274208175, 'Factory Girl')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/the-movies-dataset/movies_metadata.csv')\n",
    "data = data[:20000]\n",
    "data['overview'].fillna('', inplace = True)\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words = 'english')\n",
    "tfidf_mat = tfidf.fit_transform(data['overview'])\n",
    "\n",
    "# 데이터프레임 생성\n",
    "tfidf_df = pd.DataFrame(tfidf_mat.toarray())\n",
    "\n",
    "# 코사인 유사도 구하는 함수\n",
    "def sim_cos(X, Y):\n",
    "    return np.dot(X, Y) / ((norm(X) * norm(Y)) + 1e-7)\n",
    "\n",
    "# 영화 인덱스와 유사도를 묶어서 리스트로 만드는 함수\n",
    "def top_match(data, movie, simf = sim_cos):\n",
    "    simList = []\n",
    "    for i in data.index:\n",
    "        if movie != i:\n",
    "            simList.append((simf(data.loc[movie, :], data.loc[i, :]), i))\n",
    "    return simList\n",
    "\n",
    "# 유사도가 높은 영화 10개를 영화 제목과 함께 출력\n",
    "movieList = []\n",
    "for sim, m_id in sorted(top_match(tfidf_df, 0), reverse = True):\n",
    "    movieList.append((sim, data.loc[m_id, 'title']))\n",
    "movieList[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
